{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65561e9-44db-4524-86c8-d22c678b3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from memory_profiler import profile\n",
    "import heapq\n",
    "from collections import deque\n",
    "import time\n",
    "from typing import List, Tuple, Dict, Set\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from PIL import Image  # For reading PNG files\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Node:\n",
    "    x: int\n",
    "    y: int\n",
    "    g_cost: float = float('inf')\n",
    "    h_cost: float = 0\n",
    "    parent: 'Node' = None\n",
    "\n",
    "    @property\n",
    "    def f_cost(self) -> float:\n",
    "        return self.g_cost + self.h_cost\n",
    "\n",
    "    def __lt__(self, other: 'Node') -> bool:\n",
    "        return self.f_cost < other.f_cost\n",
    "\n",
    "\n",
    "class GridMap:\n",
    "    def __init__(self, grid: np.ndarray):\n",
    "        \"\"\"\n",
    "        grid: a 2D numpy array with values:\n",
    "          0 -> free cell\n",
    "          1 -> obstacle\n",
    "        \"\"\"\n",
    "        self.grid = grid\n",
    "        self.height, self.width = grid.shape\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, filepath: str) -> 'GridMap':\n",
    "        \"\"\"\n",
    "        Load grid from a PNG file. Adjust thresholding logic\n",
    "        based on whether black or white is an obstacle.\n",
    "        \"\"\"\n",
    "        if not filepath.lower().endswith('.png'):\n",
    "            raise ValueError(\"Only .png files are supported by from_file().\")\n",
    "\n",
    "        # Open PNG as grayscale\n",
    "        img = Image.open(filepath).convert('L')\n",
    "        arr = np.array(img)\n",
    "\n",
    "        # Example threshold: black (pixel < 128) => obstacle => 1, else => 0\n",
    "        grid = (arr < 128).astype(int)\n",
    "\n",
    "        return cls(grid)\n",
    "\n",
    "    def is_valid_position(self, x: int, y: int) -> bool:\n",
    "        \"\"\"Check if position is within grid bounds and not an obstacle (0 -> free).\"\"\"\n",
    "        return (\n",
    "            0 <= x < self.width\n",
    "            and 0 <= y < self.height\n",
    "            and self.grid[y, x] == 0\n",
    "        )\n",
    "\n",
    "    def get_neighbors(self, node: 'Node') -> List[tuple]:\n",
    "        \"\"\"Get valid neighboring positions (up, right, down, left).\"\"\"\n",
    "        directions = [(0, 1), (1, 0), (0, -1), (-1, 0)]\n",
    "        neighbors = []\n",
    "        for dx, dy in directions:\n",
    "            new_x, new_y = node.x + dx, node.y + dy\n",
    "            if self.is_valid_position(new_x, new_y):\n",
    "                neighbors.append((new_x, new_y))\n",
    "        return neighbors\n",
    "\n",
    "\n",
    "class Bresenham:\n",
    "    @staticmethod\n",
    "    def get_line(start: tuple, end: tuple) -> List[tuple]:\n",
    "        \"\"\"Generate points along Bresenham's line between start and end.\"\"\"\n",
    "        x1, y1 = start\n",
    "        x2, y2 = end\n",
    "        points = []\n",
    "        dx = abs(x2 - x1)\n",
    "        dy = abs(y2 - y1)\n",
    "        x, y = x1, y1\n",
    "        sx = 1 if x1 < x2 else -1\n",
    "        sy = 1 if y1 < y2 else -1\n",
    "\n",
    "        if dx > dy:\n",
    "            err = dx / 2.0\n",
    "            while x != x2:\n",
    "                points.append((x, y))\n",
    "                err -= dy\n",
    "                if err < 0:\n",
    "                    y += sy\n",
    "                    err += dx\n",
    "                x += sx\n",
    "        else:\n",
    "            err = dy / 2.0\n",
    "            while y != y2:\n",
    "                points.append((x, y))\n",
    "                err -= dx\n",
    "                if err < 0:\n",
    "                    x += sx\n",
    "                    err += dy\n",
    "                y += sy\n",
    "\n",
    "        points.append((x2, y2))\n",
    "        return points\n",
    "\n",
    "\n",
    "class PathFinder:\n",
    "    def __init__(self, grid_map: GridMap):\n",
    "        self.grid_map = grid_map\n",
    "\n",
    "    @staticmethod\n",
    "    def manhattan_distance(p1: tuple, p2: tuple) -> float:\n",
    "        \"\"\"Calculate Manhattan distance between two points.\"\"\"\n",
    "        return abs(p1[0] - p2[0]) + abs(p1[1] - p2[1])\n",
    "\n",
    "    @profile\n",
    "    def a_star(self, start: tuple, end: tuple,\n",
    "               ils_region: Set[tuple] = None) -> (List[tuple], Dict):\n",
    "        \"\"\"A* pathfinding algorithm.\"\"\"\n",
    "        start_time = time.time()\n",
    "        start_node = Node(start[0], start[1], g_cost=0)\n",
    "        start_node.h_cost = self.manhattan_distance(start, end)\n",
    "\n",
    "        open_set = [start_node]\n",
    "        closed_set = set()\n",
    "        nodes = {start: start_node}\n",
    "\n",
    "        while open_set:\n",
    "            current = heapq.heappop(open_set)\n",
    "\n",
    "            if (current.x, current.y) == end:\n",
    "                path = []\n",
    "                while current:\n",
    "                    path.append((current.x, current.y))\n",
    "                    current = current.parent\n",
    "\n",
    "                metrics = {\n",
    "                    'time': time.time() - start_time,\n",
    "                    'visited_nodes': len(closed_set),\n",
    "                    'path_length': len(path)\n",
    "                }\n",
    "                return path[::-1], metrics\n",
    "\n",
    "            closed_set.add((current.x, current.y))\n",
    "\n",
    "            for nx, ny in self.grid_map.get_neighbors(current):\n",
    "                if ils_region and (nx, ny) not in ils_region:\n",
    "                    continue\n",
    "\n",
    "                if (nx, ny) in closed_set:\n",
    "                    continue\n",
    "\n",
    "                next_pos = (nx, ny)\n",
    "                if next_pos not in nodes:\n",
    "                    nodes[next_pos] = Node(nx, ny)\n",
    "                next_node = nodes[next_pos]\n",
    "\n",
    "                tentative_g = current.g_cost + 1\n",
    "\n",
    "                if tentative_g < next_node.g_cost:\n",
    "                    next_node.parent = current\n",
    "                    next_node.g_cost = tentative_g\n",
    "                    next_node.h_cost = self.manhattan_distance(next_pos, end)\n",
    "\n",
    "                    if next_node not in open_set:\n",
    "                        heapq.heappush(open_set, next_node)\n",
    "\n",
    "        return [], {\n",
    "            'time': time.time() - start_time,\n",
    "            'visited_nodes': len(closed_set),\n",
    "            'path_length': 0\n",
    "        }\n",
    "\n",
    "    @profile\n",
    "    def dijkstra(self, start: tuple, end: tuple,\n",
    "                 ils_region: Set[tuple] = None) -> (List[tuple], Dict):\n",
    "        \"\"\"Dijkstra's algorithm implementation.\"\"\"\n",
    "        start_time = time.time()\n",
    "        start_node = Node(start[0], start[1], g_cost=0)\n",
    "\n",
    "        open_set = [start_node]\n",
    "        closed_set = set()\n",
    "        nodes = {start: start_node}\n",
    "\n",
    "        while open_set:\n",
    "            current = heapq.heappop(open_set)\n",
    "\n",
    "            if (current.x, current.y) == end:\n",
    "                path = []\n",
    "                while current:\n",
    "                    path.append((current.x, current.y))\n",
    "                    current = current.parent\n",
    "\n",
    "                metrics = {\n",
    "                    'time': time.time() - start_time,\n",
    "                    'visited_nodes': len(closed_set),\n",
    "                    'path_length': len(path)\n",
    "                }\n",
    "                return path[::-1], metrics\n",
    "\n",
    "            closed_set.add((current.x, current.y))\n",
    "\n",
    "            for nx, ny in self.grid_map.get_neighbors(current):\n",
    "                if ils_region and (nx, ny) not in ils_region:\n",
    "                    continue\n",
    "                if (nx, ny) in closed_set:\n",
    "                    continue\n",
    "\n",
    "                next_pos = (nx, ny)\n",
    "                if next_pos not in nodes:\n",
    "                    nodes[next_pos] = Node(nx, ny)\n",
    "                next_node = nodes[next_pos]\n",
    "\n",
    "                tentative_g = current.g_cost + 1\n",
    "\n",
    "                if tentative_g < next_node.g_cost:\n",
    "                    next_node.parent = current\n",
    "                    next_node.g_cost = tentative_g\n",
    "\n",
    "                    if next_node not in open_set:\n",
    "                        heapq.heappush(open_set, next_node)\n",
    "\n",
    "        return [], {\n",
    "            'time': time.time() - start_time,\n",
    "            'visited_nodes': len(closed_set),\n",
    "            'path_length': 0\n",
    "        }\n",
    "\n",
    "    @profile\n",
    "    def bfs(self, start: tuple, end: tuple,\n",
    "            ils_region: Set[tuple] = None) -> (List[tuple], Dict):\n",
    "        \"\"\"Breadth-First Search implementation.\"\"\"\n",
    "        start_time = time.time()\n",
    "        visited = set([start])\n",
    "        queue = deque([(start, [start])])\n",
    "\n",
    "        while queue:\n",
    "            current, path = queue.popleft()\n",
    "\n",
    "            if current == end:\n",
    "                metrics = {\n",
    "                    'time': time.time() - start_time,\n",
    "                    'visited_nodes': len(visited),\n",
    "                    'path_length': len(path)\n",
    "                }\n",
    "                return path, metrics\n",
    "\n",
    "            node = Node(current[0], current[1])\n",
    "            for nx, ny in self.grid_map.get_neighbors(node):\n",
    "                if ils_region and (nx, ny) not in ils_region:\n",
    "                    continue\n",
    "                if (nx, ny) not in visited:\n",
    "                    visited.add((nx, ny))\n",
    "                    new_path = path + [(nx, ny)]\n",
    "                    queue.append(((nx, ny), new_path))\n",
    "\n",
    "        return [], {\n",
    "            'time': time.time() - start_time,\n",
    "            'visited_nodes': len(visited),\n",
    "            'path_length': 0\n",
    "        }\n",
    "\n",
    "    @profile\n",
    "    def dfs(self, start: tuple, end: tuple,\n",
    "            ils_region: Set[tuple] = None) -> (List[tuple], Dict):\n",
    "        \"\"\"Depth-First Search implementation.\"\"\"\n",
    "        start_time = time.time()\n",
    "        visited = set([start])\n",
    "        stack = [(start, [start])]\n",
    "\n",
    "        while stack:\n",
    "            current, path = stack.pop()\n",
    "\n",
    "            if current == end:\n",
    "                metrics = {\n",
    "                    'time': time.time() - start_time,\n",
    "                    'visited_nodes': len(visited),\n",
    "                    'path_length': len(path)\n",
    "                }\n",
    "                return path, metrics\n",
    "\n",
    "            node = Node(current[0], current[1])\n",
    "            for nx, ny in self.grid_map.get_neighbors(node):\n",
    "                if ils_region and (nx, ny) not in ils_region:\n",
    "                    continue\n",
    "                if (nx, ny) not in visited:\n",
    "                    visited.add((nx, ny))\n",
    "                    new_path = path + [(nx, ny)]\n",
    "                    stack.append(((nx, ny), new_path))\n",
    "\n",
    "        return [], {\n",
    "            'time': time.time() - start_time,\n",
    "            'visited_nodes': len(visited),\n",
    "            'path_length': 0\n",
    "        }\n",
    "\n",
    "    @profile\n",
    "    def best_first_search(self, start: tuple, end: tuple,\n",
    "                          ils_region: Set[tuple] = None) -> (List[tuple], Dict):\n",
    "        \"\"\"Best-First Search implementation.\"\"\"\n",
    "        start_time = time.time()\n",
    "        start_node = Node(start[0], start[1])\n",
    "        start_node.h_cost = self.manhattan_distance(start, end)\n",
    "\n",
    "        open_set = [start_node]\n",
    "        closed_set = set()\n",
    "        nodes = {start: start_node}\n",
    "\n",
    "        while open_set:\n",
    "            current = heapq.heappop(open_set)\n",
    "\n",
    "            if (current.x, current.y) == end:\n",
    "                path = []\n",
    "                while current:\n",
    "                    path.append((current.x, current.y))\n",
    "                    current = current.parent\n",
    "\n",
    "                metrics = {\n",
    "                    'time': time.time() - start_time,\n",
    "                    'visited_nodes': len(closed_set),\n",
    "                    'path_length': len(path)\n",
    "                }\n",
    "                return path[::-1], metrics\n",
    "\n",
    "            closed_set.add((current.x, current.y))\n",
    "\n",
    "            for nx, ny in self.grid_map.get_neighbors(current):\n",
    "                if ils_region and (nx, ny) not in ils_region:\n",
    "                    continue\n",
    "                if (nx, ny) in closed_set:\n",
    "                    continue\n",
    "\n",
    "                next_pos = (nx, ny)\n",
    "                if next_pos not in nodes:\n",
    "                    nodes[next_pos] = Node(nx, ny)\n",
    "                next_node = nodes[next_pos]\n",
    "\n",
    "                # Best-First uses heuristic only (no g_cost)\n",
    "                if next_node not in open_set:\n",
    "                    next_node.parent = current\n",
    "                    next_node.h_cost = self.manhattan_distance(next_pos, end)\n",
    "                    heapq.heappush(open_set, next_node)\n",
    "\n",
    "        return [], {\n",
    "            'time': time.time() - start_time,\n",
    "            'visited_nodes': len(closed_set),\n",
    "            'path_length': 0\n",
    "        }\n",
    "\n",
    "\n",
    "class Visualizer:\n",
    "    @staticmethod\n",
    "    def plot_side_by_side(\n",
    "        grid: np.ndarray,\n",
    "        path_standard: List[tuple],\n",
    "        path_ils: List[tuple],\n",
    "        ils_region: Set[tuple],\n",
    "        algo_name: str,\n",
    "        map_name: str,\n",
    "        ax_titles=(\"Standard\", \"Incremental Line Search\")\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Plot a side-by-side comparison of Standard vs. ILS\n",
    "        on a single figure for a given algorithm and map.\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "        # Left: Standard\n",
    "        Visualizer.plot_grid_with_path(\n",
    "            grid=grid,\n",
    "            path=path_standard,\n",
    "            ils_region=None,\n",
    "            title=f\"{algo_name} - {ax_titles[0]}\",\n",
    "            ax=axes[0]\n",
    "        )\n",
    "\n",
    "        # Right: ILS\n",
    "        Visualizer.plot_grid_with_path(\n",
    "            grid=grid,\n",
    "            path=path_ils,\n",
    "            ils_region=ils_region,\n",
    "            title=f\"{algo_name} - {ax_titles[1]}\",\n",
    "            ax=axes[1]\n",
    "        )\n",
    "\n",
    "        fig.suptitle(f\"{algo_name} Comparison on {map_name}\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save in 'analysis_plots' directory\n",
    "        os.makedirs(\"analysis_plots\", exist_ok=True)\n",
    "        filename = f\"{map_name}_{algo_name}_comparison.png\".replace(\".png\",\"_compare.png\")\n",
    "        save_path = os.path.join(\"analysis_plots\", filename)\n",
    "        plt.savefig(save_path, dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_grid_with_path(\n",
    "        grid: np.ndarray,\n",
    "        path: List[tuple],\n",
    "        ils_region: Set[tuple] = None,\n",
    "        title: str = \"\",\n",
    "        ax: plt.Axes = None\n",
    "    ):\n",
    "        \"\"\"Plot grid with highlighted path and optional ILS region.\"\"\"\n",
    "        if ax is None:\n",
    "            _, ax = plt.subplots()\n",
    "\n",
    "        ax.imshow(grid, cmap='binary')\n",
    "\n",
    "        if ils_region and len(ils_region) > 0:\n",
    "            rr_y, rr_x = zip(*ils_region)\n",
    "            ax.scatter(rr_x, rr_y, color='yellow', alpha=0.3, s=30, label='ILS Region')\n",
    "\n",
    "        if path:\n",
    "            path_y, path_x = zip(*[(y, x) for x, y in path])\n",
    "            ax.plot(path_x, path_y, 'r-', linewidth=2, label='Path')\n",
    "\n",
    "        ax.set_title(title)\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_comparison_metrics(results_df: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Create multiple visualization types for time, visited_nodes, path_length\n",
    "        across each algorithm and approach (Standard vs. ILS).\n",
    "        \"\"\"\n",
    "        os.makedirs(\"analysis_plots\", exist_ok=True)\n",
    "\n",
    "        metrics = ['time', 'visited_nodes', 'path_length']\n",
    "\n",
    "        df_comp = results_df.copy()\n",
    "        # Add approach column\n",
    "        df_comp['approach'] = df_comp['algorithm'].apply(\n",
    "            lambda x: 'ILS' if 'ILS' in x else 'Standard'\n",
    "        )\n",
    "        # Clean the algorithm name\n",
    "        df_comp['algorithm'] = (\n",
    "            df_comp['algorithm'].str.replace(' (Standard)', '', regex=False)\n",
    "                              .str.replace(' (ILS)', '', regex=False)\n",
    "        )\n",
    "\n",
    "        # 1) Bar plots for each metric\n",
    "        plt.figure(figsize=(14, 5 * len(metrics)))\n",
    "        for i, metric in enumerate(metrics, 1):\n",
    "            plt.subplot(len(metrics), 1, i)\n",
    "            sns.barplot(data=df_comp, x='algorithm', y=metric, hue='approach', dodge=True)\n",
    "            plt.title(f'{metric.replace(\"_\", \" \").title()} Comparison')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.legend(loc='best')\n",
    "        plt.tight_layout()\n",
    "        barplot_path = os.path.join(\"analysis_plots\", \"barplots_comparison.png\")\n",
    "        plt.savefig(barplot_path, dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "        # 2) Swarm plots for each metric (to see distribution)\n",
    "        plt.figure(figsize=(14, 5 * len(metrics)))\n",
    "        for i, metric in enumerate(metrics, 1):\n",
    "            plt.subplot(len(metrics), 1, i)\n",
    "            sns.swarmplot(data=df_comp, x='algorithm', y=metric, hue='approach', dodge=True)\n",
    "            plt.title(f'Swarm Plot: {metric.replace(\"_\", \" \").title()}')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.legend(loc='best')\n",
    "        plt.tight_layout()\n",
    "        swarmplot_path = os.path.join(\"analysis_plots\", \"swarmplots_comparison.png\")\n",
    "        plt.savefig(swarmplot_path, dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "        # 3) Line plot for each metric (group by approach, each map as x-axis)\n",
    "        plt.figure(figsize=(14, 5 * len(metrics)))\n",
    "        for i, metric in enumerate(metrics, 1):\n",
    "            plt.subplot(len(metrics), 1, i)\n",
    "            sns.lineplot(data=df_comp, x='map', y=metric, hue='approach', style='algorithm', markers=True)\n",
    "            plt.title(f'Line Plot: {metric.replace(\"_\", \" \").title()} by Map')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.legend(loc='best')\n",
    "        plt.tight_layout()\n",
    "        lineplot_path = os.path.join(\"analysis_plots\", \"lineplots_comparison.png\")\n",
    "        plt.savefig(lineplot_path, dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "        # 4) Violin plot\n",
    "        plt.figure(figsize=(14, 5 * len(metrics)))\n",
    "        for i, metric in enumerate(metrics, 1):\n",
    "            plt.subplot(len(metrics), 1, i)\n",
    "            sns.violinplot(data=df_comp, x='algorithm', y=metric, hue='approach', split=True)\n",
    "            plt.title(f'Violin Plot: {metric.replace(\"_\", \" \").title()}')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.legend(loc='best')\n",
    "        plt.tight_layout()\n",
    "        violinplot_path = os.path.join(\"analysis_plots\", \"violinplots_comparison.png\")\n",
    "        plt.savefig(violinplot_path, dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "        # 5) Histogram of each metric\n",
    "        plt.figure(figsize=(14, 4 * len(metrics)))\n",
    "        for i, metric in enumerate(metrics, 1):\n",
    "            plt.subplot(len(metrics), 1, i)\n",
    "            sns.histplot(data=df_comp, x=metric, hue='approach', kde=True, multiple='stack')\n",
    "            plt.title(f'Histogram of {metric.replace(\"_\", \" \").title()}')\n",
    "            plt.legend(loc='best')\n",
    "        plt.tight_layout()\n",
    "        histplot_path = os.path.join(\"analysis_plots\", \"histograms_metrics.png\")\n",
    "        plt.savefig(histplot_path, dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "        # 6) Pairwise relationships among time, visited_nodes, path_length\n",
    "        pairplot_data = df_comp[[\"time\", \"visited_nodes\", \"path_length\", \"approach\"]]\n",
    "        g = sns.pairplot(pairplot_data, hue='approach', corner=True)\n",
    "        pairplot_path = os.path.join(\"analysis_plots\", \"pairwise_relationships.png\")\n",
    "        g.savefig(pairplot_path, dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "        # 7) Correlation heatmap among the 3 main metrics\n",
    "        corr_data = df_comp[[\"time\", \"visited_nodes\", \"path_length\"]]\n",
    "        corr_matrix = corr_data.corr()\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "        plt.title('Correlation among Time, Visited Nodes, and Path Length')\n",
    "        corr_path = os.path.join(\"analysis_plots\", \"correlation_heatmap.png\")\n",
    "        plt.savefig(corr_path, dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def display_comparison_table(results_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Display a table that compares each standard algorithm with its ILS counterpart\n",
    "        side by side AND includes a percentage improvement column.\n",
    "        Also show an aggregated improvement summary across all maps per algorithm.\n",
    "        \"\"\"\n",
    "        # 1) Parse approach and unify the base algorithm name\n",
    "        df_comp = results_df.copy()\n",
    "        df_comp['approach'] = df_comp['algorithm'].apply(\n",
    "            lambda x: 'ILS' if 'ILS' in x else 'Standard'\n",
    "        )\n",
    "        df_comp['algorithm'] = (df_comp['algorithm']\n",
    "                                .str.replace(' (Standard)', '', regex=False)\n",
    "                                .str.replace(' (ILS)', '', regex=False))\n",
    "\n",
    "        # 2) Pivot to get side-by-side columns: time_Standard, time_ILS, etc.\n",
    "        pivoted = df_comp.pivot_table(\n",
    "            index=['map', 'algorithm'], \n",
    "            columns='approach', \n",
    "            values=['time', 'visited_nodes', 'path_length']\n",
    "        )\n",
    "        pivoted.columns = ['_'.join(col).strip() for col in pivoted.columns.values]\n",
    "        pivoted = pivoted.reset_index()\n",
    "\n",
    "        # 3) Percentage improvement: \n",
    "        #    improvement_time% = ((Standard - ILS) / Standard) * 100\n",
    "        def pct_improvement(std_val, ils_val):\n",
    "            if std_val == 0:  # avoid division by zero\n",
    "                return 0\n",
    "            return ((std_val - ils_val) / std_val) * 100\n",
    "\n",
    "        pivoted['time_pct_improvement'] = pivoted.apply(\n",
    "            lambda row: pct_improvement(row.get('time_Standard', 0), \n",
    "                                        row.get('time_ILS', 0)), axis=1\n",
    "        )\n",
    "        pivoted['visited_nodes_pct_improvement'] = pivoted.apply(\n",
    "            lambda row: pct_improvement(row.get('visited_nodes_Standard', 0), \n",
    "                                        row.get('visited_nodes_ILS', 0)), axis=1\n",
    "        )\n",
    "        pivoted['path_length_pct_improvement'] = pivoted.apply(\n",
    "            lambda row: pct_improvement(row.get('path_length_Standard', 0), \n",
    "                                        row.get('path_length_ILS', 0)), axis=1\n",
    "        )\n",
    "\n",
    "        print(\"\\n== Metrics Comparison Table (Standard vs. Incremental Line Search) ==\\n\")\n",
    "        print(pivoted.to_string(index=False))\n",
    "\n",
    "        # 4) Summarize average percentage improvement across all maps by algorithm\n",
    "        improvement_summary = pivoted.groupby('algorithm', as_index=False).agg({\n",
    "            'time_pct_improvement': 'mean',\n",
    "            'visited_nodes_pct_improvement': 'mean',\n",
    "            'path_length_pct_improvement': 'mean'\n",
    "        })\n",
    "\n",
    "        print(\"\\n== Average Percentage Improvement Summary (Standard vs. ILS) ==\\n\")\n",
    "        print(improvement_summary.to_string(index=False))\n",
    "\n",
    "        # 5) Save the pivoted table and improvement summary to CSV\n",
    "        os.makedirs(\"analysis_plots\", exist_ok=True)\n",
    "        pivoted.to_csv(os.path.join(\"analysis_plots\", \"comparison_table.csv\"), index=False)\n",
    "        improvement_summary.to_csv(os.path.join(\"analysis_plots\", \"improvement_summary.csv\"), index=False)\n",
    "\n",
    "\n",
    "def create_ils_region(\n",
    "    grid_map: GridMap,\n",
    "    start: tuple,\n",
    "    end: tuple,\n",
    "    region_width_percentage: float = 0.05  # smaller width\n",
    ") -> Set[tuple]:\n",
    "    \"\"\"\n",
    "    Create an 'Incremental Line Search' region around Bresenham's line\n",
    "    from start to end. region_width_percentage determines the width \n",
    "    relative to the smallest dimension of the grid.\n",
    "    \"\"\"\n",
    "    line_points = set(Bresenham.get_line(start, end))\n",
    "    ils_region = set()\n",
    "\n",
    "    region_width = int(min(grid_map.width, grid_map.height) * region_width_percentage)\n",
    "\n",
    "    for x, y in line_points:\n",
    "        for dx in range(-region_width, region_width + 1):\n",
    "            for dy in range(-region_width, region_width + 1):\n",
    "                nx, ny = x + dx, y + dy\n",
    "                if grid_map.is_valid_position(nx, ny):\n",
    "                    ils_region.add((nx, ny))\n",
    "\n",
    "    return ils_region\n",
    "\n",
    "\n",
    "def main():\n",
    "    grid_folder = 'grid_maps'\n",
    "    results = []\n",
    "\n",
    "    if not os.path.exists(grid_folder):\n",
    "        os.makedirs(grid_folder)\n",
    "        print(f\"Created '{grid_folder}' directory. Please add .png map files and run again.\")\n",
    "        return\n",
    "\n",
    "    for filename in os.listdir(grid_folder):\n",
    "        if not filename.lower().endswith('.png'):\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nProcessing map: {filename}\")\n",
    "        filepath = os.path.join(grid_folder, filename)\n",
    "\n",
    "        try:\n",
    "            grid_map = GridMap.from_file(filepath)\n",
    "            pathfinder = PathFinder(grid_map)\n",
    "\n",
    "            # Define start and end points\n",
    "            start = (0, 0)\n",
    "            end = (grid_map.width - 1, grid_map.height - 1)\n",
    "\n",
    "            # Corridor-like region for Incremental Line Search\n",
    "            region_width_percentage = 0.05  # Adjust as needed\n",
    "            ils_region = create_ils_region(grid_map, start, end, region_width_percentage)\n",
    "\n",
    "            # List of algorithms\n",
    "            algorithms = [\n",
    "                ('A*', pathfinder.a_star),\n",
    "                ('Dijkstra', pathfinder.dijkstra),\n",
    "                ('BFS', pathfinder.bfs),\n",
    "                ('DFS', pathfinder.dfs),\n",
    "                ('Best-First', pathfinder.best_first_search)\n",
    "            ]\n",
    "\n",
    "            for algo_name, algo_func in algorithms:\n",
    "                print(f\"Running {algo_name} (Standard)...\")\n",
    "                path_standard, metrics_std = algo_func(start, end)\n",
    "                metrics_std.update({\n",
    "                    'algorithm': f\"{algo_name} (Standard)\",\n",
    "                    'map': filename,\n",
    "                    # Additional info for CSV\n",
    "                    'start_x': start[0],\n",
    "                    'start_y': start[1],\n",
    "                    'end_x': end[0],\n",
    "                    'end_y': end[1],\n",
    "                    'corridor_width': region_width_percentage,\n",
    "                })\n",
    "                results.append(metrics_std)\n",
    "\n",
    "                print(f\"Running {algo_name} (ILS)...\")\n",
    "                path_ils, metrics_ils = algo_func(start, end, ils_region)\n",
    "                metrics_ils.update({\n",
    "                    'algorithm': f\"{algo_name} (ILS)\",\n",
    "                    'map': filename,\n",
    "                    # Additional info for CSV\n",
    "                    'start_x': start[0],\n",
    "                    'start_y': start[1],\n",
    "                    'end_x': end[0],\n",
    "                    'end_y': end[1],\n",
    "                    'corridor_width': region_width_percentage,\n",
    "                })\n",
    "                results.append(metrics_ils)\n",
    "\n",
    "                # Side by side comparison for Standard vs. ILS\n",
    "                Visualizer.plot_side_by_side(\n",
    "                    grid_map.grid,\n",
    "                    path_standard,\n",
    "                    path_ils,\n",
    "                    ils_region,\n",
    "                    algo_name,\n",
    "                    filename\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if not results:\n",
    "        print(\"No results generated. Please check your PNG maps.\")\n",
    "        return\n",
    "\n",
    "    # Create DataFrame with all results\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Save all raw results to a CSV\n",
    "    # This now includes start_x, start_y, end_x, end_y, and corridor_width.\n",
    "    results_df.to_csv('pathfinding_results.csv', index=False)\n",
    "\n",
    "    # 1) Create extended plots and store them\n",
    "    Visualizer.plot_comparison_metrics(results_df)\n",
    "\n",
    "    # 2) Display & save a comparison table with % improvements\n",
    "    Visualizer.display_comparison_table(results_df)\n",
    "\n",
    "    print(\"\\nAll results have been saved to 'pathfinding_results.csv', and detailed plots/tables are in 'analysis_plots' folder.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
